\chapter{State of the Art}
\label{chapter:state-of-the-art}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introdução geral do capítulo.
% Explica ao leitor o propósito da revisão de literatura e
% como ela se conecta ao problema central da dissertação.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent
This chapter presents a comprehensive review of the current state of the art in the optimisation of water supply systems (WSS), with a particular focus on the integration of data-driven and physics-based approaches. 
The objective is to establish the theoretical and methodological foundation for the application of the DC3 (Deep Constraint Completion and Correction) algorithm in cost optimisation of water pumping operations.

First, the chapter introduces the main computational tools for hydraulic simulation, which serve as the data sources for optimisation and learning processes. 
Next, it reviews the fundamental concepts of deep learning and its applications in water management systems. 
The following sections explore optimisation methodologies, focusing on the role of hard constraints in guaranteeing operational feasibility. 
Finally, the DC3 algorithm is introduced as an innovative learning method capable of addressing the limitations of conventional optimisation techniques.

The chapter concludes with a simple illustrative example demonstrating how DC3 operates under nonlinear constraints, setting the stage for the methodological implementation described in Chapter~\ref{chap:methodology}.


\section{Hydraulic Simulation}

Several hydraulic simulators are currently available for modelling and analysing water supply systems, including EPANET\cite{rfc4}, and WaterGEMS/WaterCAD \cite{rfc30}. These tools provide efficient numerical solutions for the system of differential-algebraic equations that describe the hydraulic and water-quality dynamics of pressurised distribution networks \cite{rfc1}.

Among these, EPANET stands out as one of the most recognised and widely adopted open-source tools for water distribution modelling \cite{rfc4}. Developed by the U.S. Environmental Protection Agency, EPANET has been successfully applied for more than two decades \cite{rfc5, rfc6}. It enables the simulation of both steady-state and extended-period hydraulic behaviour, supporting the evaluation of flow, pressure, head loss, and water quality over time. 

In this research, EPANET is used to generate the hydraulic data necessary for the optimisation framework. Its flexibility and computational efficiency make it suitable for integration with machine learning and deep optimisation methods, such as the one proposed in this dissertation.

\section{Deep Learning}

\subsection{Neural Networks}

The fundamental concept of artificial neural networks (ANNs) was first introduced in 1943 as a mathematical abstraction of the biological neuron \cite{rfc23}. A typical ANN architecture consists of layers of interconnected units (neurons), each performing a weighted summation of its inputs followed by a nonlinear activation. 

Let $x_i$ be the input vector, $w_{ij}$ the connection weights, and $b_j$ the bias of neuron $j$. The pre-activation and activation are computed as:
\[
z_j = \sum_i w_{ij}x_i + b_j, \qquad a_j = \phi(z_j),
\]
where $\phi(\cdot)$ is the activation function. Common activation functions include the sigmoid, hyperbolic tangent, rectified linear unit (ReLU), and Gaussian error linear unit (GELU).

The combination of multiple layers allows neural networks to approximate highly nonlinear mappings between inputs and outputs, forming the foundation for more advanced models in deep learning \cite{rfc27}.

\subsection{Deep Learning}

Deep Learning (DL) is a subfield of machine learning based on deep neural architectures capable of automatically extracting hierarchical features from large and complex datasets. Unlike traditional machine learning methods, which rely on handcrafted feature extraction, deep learning models learn these representations directly from raw data through backpropagation \cite{rfc22, rfc23, rfc24}.

The scalability of deep learning has been enhanced by advances in parallel computing (GPUs), cloud-based training platforms, and open-source frameworks such as TensorFlow, PyTorch, and Keras. These developments have enabled DL models to achieve state-of-the-art performance across domains including natural language processing, computer vision, and control systems \cite{rfc26}.

\subsection{Deep Learning in Water Supply Systems}

The growing demand for energy efficiency and sustainability in water supply systems (WSS) has accelerated the use of data-driven approaches such as Machine Learning (ML) and Deep Learning (DL) for optimisation, monitoring, and predictive control.

Using data generated by hydraulic simulators like EPANET or collected via SCADA systems, DL models can learn to predict hydraulic states, identify anomalies, and optimise control actions. Recent studies highlight several promising applications: 
\begin{itemize}
    \item anomaly detection in water distribution systems \cite{rfc12};
    \item pressure prediction using hybrid models such as CNN-GRU with attention mechanisms \cite{rfc11};
    \item leak detection using convolutional networks and kriging interpolation \cite{rfc13};
    \item real-time intelligent pump scheduling based on consumption forecasting and tariff variations \cite{rfc9}.
\end{itemize}

Although these approaches show excellent predictive capability, they typically do not guarantee compliance with physical or operational constraints. This limitation motivates the integration of constraint-aware deep learning techniques—such as the DC3 algorithm—for fast approximate solutions to optimisation problems.




\section{Optimisation in Water Supply Systems}

Optimisation plays a fundamental role in engineering systems, aiming to minimise or maximise an objective function subject to a set of operational constraints \cite{rfc19}. In water supply systems, the primary goal is often the reduction of energy costs associated with pumping operations while maintaining required service levels and hydraulic feasibility \cite{rfc7, rfc8}.

Water supply pumping stations are responsible for the majority of energy consumption in WSS—often exceeding 80\% of total operational costs \cite{rfc8}. Energy cost optimisation can therefore significantly enhance the economic and environmental sustainability of utilities. Typical optimisation strategies include pump replacement, schedule reconfiguration, and dynamic operation aligned with time-varying electricity tariffs \cite{rfc20}.

A general optimisation problem can be formulated as follows:

\begin{equation}
\begin{aligned}
\min_{x} \quad & f(x) \\
\text{s.t.} \quad & g(x) \le 0, \\
& h(x) = 0,
\end{aligned}
\end{equation}
where $f(x)$ is the objective function (e.g., energy cost), $g(x)$ and $h(x)$ represent inequality and equality constraints, respectively. In the WSS context, these constraints enforce hydraulic limits such as pressure bounds, reservoir capacities, and operational schedules.

Optimisation problems in water systems can be linear or nonlinear, convex or non-convex, and may involve continuous or discrete decision variables. Common techniques include linear programming (LP), nonlinear programming (NLP), and mixed-integer programming (MIP). Recent approaches have also incorporated hybrid or metaheuristic methods to handle large-scale nonlinear formulations efficiently \cite{rfc29}.

\section{Hard Constraints and Constrained Learning}

Hard constraints refer to non-negotiable physical or operational rules that must be strictly satisfied in optimisation problems \cite{rfc16}. In WSS, these include pressure limits, storage capacities, and energy availability. Violation of such constraints can lead to hydraulic infeasibility or system failure \cite{rfc17}.

Traditional gradient-based learning methods are efficient for unconstrained optimisation but often struggle to enforce strict equality or inequality constraints \cite{rfc10}. Applying classical constrained solvers, such as Sequential Quadratic Programming (SQP), to deep neural models is non-trivial due to the high-dimensional, nonlinear, and non-convex parameter spaces involved \cite{rfc18}.
To address these challenges, constraint-aware learning frameworks have been developed. These include Physics-Informed Neural Networks (PINNs) and Constrained Neural Fields, which embed physical relationships into the learning process \cite{rfc15, rfc10, rfc16}. Among these, the DC3 (Deep Constraint Completion and Correction) algorithm provides a general mechanism to ensure feasibility throughout both training and inference.

