{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "from functools import reduce\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "torch.xpu.is_available()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = os.path.join('datasets', 'dc_wss', 'dc_wss_dataset_dc5_ex500')\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "file_path = os.path.join('models', 'model_2025-03-29_02-29-15_dcwss_samples500_epochs100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNSolver(nn.Module):\n",
    "    def __init__(self, data, args):\n",
    "        super().__init__()\n",
    "        self._data = data\n",
    "        self._args = args\n",
    "        layer_sizes = [data.xdim, self._args['hiddenSize'], self._args['hiddenSize']]\n",
    "        layers = reduce(operator.add,\n",
    "            [[nn.Linear(a,b), nn.BatchNorm1d(b), nn.ReLU(), nn.Dropout(p=0.2)]\n",
    "                for a,b in zip(layer_sizes[0:-1], layer_sizes[1:])])\n",
    "        \n",
    "        output_dim = data.ydim - data.nknowns        \n",
    "\n",
    "        if self._args['useCompl']:\n",
    "            layers += [nn.Linear(layer_sizes[-1], output_dim - data.neq)]            \n",
    "        else:\n",
    "            layers += [nn.Linear(layer_sizes[-1], output_dim)] \n",
    "            \n",
    "        for layer in layers:\n",
    "            if type(layer) is nn.Linear:\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('X ', x[0])\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self._args['useCompl']:\n",
    "            result = self._data.complete_partial(x, out)\n",
    "            return result\n",
    "        else:\n",
    "            \n",
    "            if self._args['probType'] == 'dc_wss':\n",
    "                out = nn.Sigmoid()(out)\n",
    "            \n",
    "            result = self._data.process_output(x, out)\n",
    "            #print('Out ', out[0])\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNSolver(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (5): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=200, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'probType': 'dc_wss', 'hiddenSize': 200, 'useCompl': False, 'corrMode': 'full'}\n",
    "\n",
    "newModel = NNSolver(data, args)\n",
    "\n",
    "newModel.load_state_dict(torch.load(file_path, map_location=torch.device('cpu')))\n",
    "\n",
    "newModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "input_data = torch.tensor([[1,5,6,7,17,2,0.9,0.9,0.9,1]])\n",
    "\n",
    "#input_data = torch.tensor([[1,9,12,16,20,1.4,1,0.6,1,2]])\n",
    "output_data = newModel(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([[ 1.0000,  5.0000,  6.0000,  7.0000, 17.0000,  2.0000,  0.9000,  0.9000,\n",
      "          0.9000,  1.0000]])\n",
      "Output:  tensor([[10.0000, 15.0000, 17.0000, 19.0000, 21.0000,  0.6978,  2.0000,  1.9507,\n",
      "          2.0000,  3.0000]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print('Input: ', input_data)\n",
    "print('Output: ', output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-1.59004211, -1.14501953, -4.25704193, -2.9822464 , -2.9822464 ,\n",
      "       -1.71475983, -1.74835968, -0.49360657, -0.49360657,  1.37815857,\n",
      "        1.37815857])]\n",
      "- - -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "130.65090663283374"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import test_level as tl\n",
    "\n",
    "output_data = output_data.detach().numpy().tolist()\n",
    "\n",
    "tl.gT(output_data[0])\n",
    "print('- - -')\n",
    "tl.obj_fn(output_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"xpu\" if torch.xpu.is_available() else \"cpu\")\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.xpu.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0000,  4.0000,  9.0000,  ...,  2.7583,  2.7608,  2.4257],\n",
       "        [ 0.0000,  3.0000,  7.0000,  ...,  3.3119,  2.9154,  0.2704],\n",
       "        [ 9.0000, 11.0000, 15.0000,  ...,  1.4648,  3.6794,  0.1000],\n",
       "        ...,\n",
       "        [ 1.0000,  3.0000,  9.0000,  ...,  3.6602,  1.7535,  3.8391],\n",
       "        [ 1.0000,  3.0000,  9.0000,  ...,  0.3673,  2.0807,  0.1000],\n",
       "        [ 0.0000,  2.0000,  8.0000,  ...,  3.1508,  4.1285,  1.0117]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "#torch.unsqueeze(x, 0)\n",
    "print(torch.squeeze(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import OptimAuxFunctionsV2 as opt_func\n",
    "import torch\n",
    "import data_system as ds\n",
    "import warnings\n",
    "from scipy import optimize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_sys = ds.data_system([5],[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0026e-06, 4.9972e+00, 5.0980e+00, 2.3895e+01, 2.3900e+01, 4.9975e+00,\n",
      "        1.0092e-01, 1.0806e-01, 9.9979e-02, 1.0002e-01], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "y = [5.0026e-06, 4.9972e+00, 5.0980e+00, 2.3895e+01, 2.3900e+01, 4.9975e+00,\n",
    "        1.0092e-01, 1.0806e-01, 9.9979e-02, 1.0002e-01]\n",
    "y = torch.tensor(y, requires_grad=True)\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.0000,  7.7450,  7.7450,  7.8224,  7.8224,  7.9076, -4.6270, -4.5528,\n",
      "        -4.6117, -4.5528], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "log_tank = opt_func.TanksOptimizationLog()\n",
    "\n",
    "resultado = opt_func.gT(y,data_sys, 0, log_tank)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "jacobiano = torch.autograd.functional.jacobian(\n",
    "    lambda y_: opt_func.gT(y_, data_sys, 0, log_tank), y\n",
    ")\n",
    "print(jacobiano.shape)\n",
    "print(jacobiano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "resultado2 = optimize.approx_fprime(\n",
    "    y.detach().numpy(), lambda y_: opt_func.gT(y_, data_sys, 0, log_tank), 1e-8\n",
    ")\n",
    "\n",
    "print(resultado2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0026e-06, 4.9972e+00, 5.0980e+00, 2.3895e+01, 2.3900e+01, 4.9975e+00,\n",
      "        1.0092e-01, 1.0806e-01, 9.9979e-02, 1.0002e-01], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "out = (y+1).pow(2).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.0000,  35.9664,  37.1856, 619.7610, 620.0100,  35.9700,   1.2120,\n",
      "          1.2278,   1.2100,   1.2100], grad_fn=<TBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 7.],\n",
      "        [9., 1.],\n",
      "        [2., 1.]])\n",
      "tensor([1245.0464, 8105.8022,   10.1073])\n",
      "tensor([[[1.4841e+02, 1.0966e+03],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [8.1031e+03, 2.7183e+00],\n",
      "         [0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [7.3891e+00, 2.7183e+00]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[5,7],[9,1],[2,1]],dtype=torch.float32)\n",
    "\n",
    "def exp_reducer(x):\n",
    "    return x.exp().sum(dim=1)\n",
    "\n",
    "exp_reducer(x)\n",
    "\n",
    "resultado = torch.autograd.functional.jacobian(exp_reducer, x)\n",
    "\n",
    "print(x)\n",
    "print(exp_reducer(x))\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gt = opt_func.gT(y, data_sys, 0, log_tank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_gt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mtcd\\Documents\\Codes\\dc3-wss\\.venv\\Lib\\site-packages\\torch\\autograd\\functional.py:676\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    673\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    674\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 676\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    677\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(\n\u001b[0;32m    678\u001b[0m     outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m )\n\u001b[0;32m    680\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "torch.autograd.functional.jacobian(result_gt.unsqueeze(0), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0000,  7.7450,  7.7450,  7.8224,  7.8224,  7.9076, -4.6270, -4.5528,\n",
       "         -4.6117, -4.5528]], dtype=torch.float64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_gt.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
